{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from stabilvol.utility import functions as f\n",
    "\n",
    "DATABASE = 'data/processed/trapezoidal_selection/stabilvol.sqlite'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba9e910dcf1f029"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.path.exists(DATABASE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4936d99282cf003"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f.list_database_thresholds(DATABASE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ec2b50c4edacc6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(DATABASE)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Query the database to get all table names\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "t1 = -0.1\n",
    "t2 = -1.5\n",
    "\n",
    "t1_string = f.stringify_threshold(t1)\n",
    "t2_string = f.stringify_threshold(t2)\n",
    "\n",
    "df = pd.read_sql_query(f'SELECT * from stabilvol_{t1_string}_{t2_string}', conn)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80b4645ae48f04aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "VOL_LIMIT = 0.05\n",
    "MARKET = 'UN'\n",
    "df = df.query('Volatility < @VOL_LIMIT and Market == @MARKET')\n",
    "df.plot(x='Volatility', y='FHT', figsize=(12, 8), kind='scatter')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "979fe4602ac813bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def error_on_the_mean(values):\n",
    "    return np.std(values)/np.sqrt(len(values))\n",
    "\n",
    "def plot_mean_range(group):\n",
    "    bins_margins = group.index.categories.left.values\n",
    "    mfht = group['mean']\n",
    "    error = group['standard_error']\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.plot(bins_margins, mfht)\n",
    "    ax.fill_between(bins_margins, mfht - error, mfht + error, alpha=0.2)\n",
    "    ax.set_xlabel('Volatility')\n",
    "    ax.set_ylabel('FHT')\n",
    "    ax.set_title(f'FHT vs Volatility for {MARKET} market')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b33b69e77c7e413f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the number of bins\n",
    "N_BINS = 1000\n",
    "\n",
    "# Use qcut to bin 'Volatility' values\n",
    "df['Bins'] = pd.qcut(df['Volatility'], N_BINS, duplicates='drop')\n",
    "\n",
    "# Group by the bins and calculate the mean and standard error of 'value'\n",
    "grouped = df.groupby('Bins')['FHT'].agg(['mean', error_on_the_mean, 'size'])\n",
    "\n",
    "# Rename the columns\n",
    "grouped.columns = ['mean', 'standard_error', 'count']\n",
    "\n",
    "plot_mean_range(grouped)\n",
    "print(grouped['count'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e3b44dbc16fe92c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Idea 1: Fit a Function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "447ff8a2075d9316"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the logistic function\n",
    "def logistic(x, x0, k, ymax):\n",
    "    return ymax / (1 + np.exp(-k*(x-x0)))\n",
    "\n",
    "def custom_function(x, scale1, scale2, a, b, c, d):\n",
    "    y1 = scale1 / (1 + np.exp(-a*(x-b)))\n",
    "    y2 = scale2 * np.exp(-c*(x)) + d\n",
    "    return y1 * y2\n",
    "\n",
    "from scipy.stats import skewnorm\n",
    "# Define the skewed Gaussian function\n",
    "def skewed_gaussian(x, ymax, a, loc, scale):\n",
    "    skwd = skewnorm.pdf(x, a, loc, scale)\n",
    "    baseline = 15 * ymax * (1 - np.exp(-10*(x-loc)))\n",
    "    return ymax*skwd + baseline\n",
    "\n",
    "def polynomial(x, a0, a1, a2, a3, a4, a5, a6, a7, a8, a9, a10):\n",
    "    return a0 + a1*x + a2*x**2 + a3*x**3 + a4*x**4 + a5*x**5 + a6*x**6 + a7*x**7 + a8*x**8 + a9*x**9 + a10*x**10\n",
    "\n",
    "function = polynomial\n",
    "\n",
    "initial_guess = [20, 10, 0.05, 0.1]\n",
    "\n",
    "x = grouped.index.categories.left.values\n",
    "y = grouped['mean'].values\n",
    "y_err = grouped['standard_error'].values\n",
    "\n",
    "# Fit the logistic function to the data\n",
    "popt, pcov = curve_fit(polynomial, x, y)\n",
    "\n",
    "# Print the optimal parameters\n",
    "print(f\"x0 = {popt[0]}, k = {popt[1]}, ymax = {popt[2]}\")\n",
    "\n",
    "# Plot the original data and the fitted curve\n",
    "plt.errorbar(x, y, yerr=y_err, fmt='o')\n",
    "plt.plot(x, function(x, *popt), 'r')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c5980bc6a200d79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit a polynomial to the data\n",
    "coeffs = np.polyfit(x, y, 12)\n",
    "\n",
    "# Create a polynomial function from the coefficients\n",
    "fitted_poly = np.poly1d(coeffs)\n",
    "\n",
    "# Generate y-values for the fitted curve\n",
    "y_fitted = fitted_poly(x)\n",
    "\n",
    "# Print the coefficients\n",
    "print(f\"Coefficients: {coeffs}\")\n",
    "\n",
    "# Plot the original data and the fitted curve\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_fitted, 'r')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "273f5deac8410d88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Idea 2: Giustify a Decent Fit\n",
    "\n",
    "Maybe while the fit does not catch the real maximum, it can be robust to changing the number of bins."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58e5e9f3aec4123e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for deg in [5, 7, 10, 12, 14, 16]:\n",
    "    print(f'Fitting to Degree {deg} Polynomial')\n",
    "    curve_params = {}\n",
    "    for nbins in [250, 300, 500, 700, 1000, 2000]:\n",
    "        # Use qcut to bin 'Volatility' values\n",
    "        df['Bins'] = pd.qcut(df['Volatility'], nbins, duplicates='drop')\n",
    "        \n",
    "        # Group by the bins and calculate the mean and standard error of 'value'\n",
    "        grouped = df.groupby('Bins')['FHT'].agg(['mean', error_on_the_mean, 'size'])\n",
    "        \n",
    "        x = grouped.index.categories.left.values\n",
    "        y = grouped['mean'].values\n",
    "        \n",
    "        max_value = grouped['mean'].max()\n",
    "        idxmax = grouped['mean'].idxmax()\n",
    "    \n",
    "        # Fit a polynomial of degree 2 to the data\n",
    "        coeffs = np.polyfit(x, y, deg)\n",
    "        x_fit = np.linspace(0, 0.05, 1000)\n",
    "        y_fitted = np.poly1d(coeffs)(x_fit)\n",
    "        \n",
    "        # plt.scatter(x, y)\n",
    "        # plt.plot(x_fit, y_fitted, 'r')\n",
    "        # plt.show()\n",
    "        \n",
    "        curve_params[nbins] = (max_value, idxmax, y_fitted.max(), x[y_fitted.argmax()])\n",
    "        \n",
    "    fig, axs = plt.subplots(3, 1, figsize=(12, 8))\n",
    "    # axs[0].plot(curve_params.keys(), [x[0] for x in curve_params.values()])\n",
    "    axs[0].plot(curve_params.keys(), [x[2] for x in curve_params.values()])\n",
    "    axs[1].plot(curve_params.keys(), [x[3] for x in curve_params.values()])\n",
    "    axs[2].scatter([x[3] for x in curve_params.values()], [x[2] for x in curve_params.values()])\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6f16d295f582664"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Idea 3: Use a Criterion to Choose Bins\n",
    "\n",
    "We can iterate the cutting until we find that at best N points are in each bin"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2305911a321a57ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = 1000\n",
    "nbins = 50\n",
    "def select_bins(df, max_n=1000):\n",
    "    nbins = 50\n",
    "    \n",
    "    while True:\n",
    "        # Use qcut to bin 'Volatility' values\n",
    "        df['Bins'] = pd.qcut(df['Volatility'], nbins, duplicates='drop')\n",
    "        \n",
    "        # Group by the bins and calculate the mean and standard error of 'value'\n",
    "        grouped = df.groupby('Bins')['FHT'].agg(['mean', error_on_the_mean, 'size'])\n",
    "        count = grouped['size'].min()\n",
    "        \n",
    "        if count < max_n:\n",
    "            break\n",
    "        else:\n",
    "            nbins += 50\n",
    "    return grouped\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f89779c9920d52f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "market = 'UN'\n",
    "vol_limit = 1\n",
    "\n",
    "fig, axs = plt.subplots(3, 5, figsize=(12, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "selected_tables = f.list_database_tables(DATABASE)[:15]\n",
    "\n",
    "for i, table_name in enumerate(selected_tables):\n",
    "    \n",
    "    ax = axs[i]\n",
    "    \n",
    "    df = pd.read_sql_query(f'SELECT * from {table_name[0]}', conn)\n",
    "    df = df.query('Volatility < @vol_limit and Market == @market')\n",
    "    \n",
    "    grouped_data = select_bins(df)\n",
    "    print(len(grouped_data))\n",
    "    \n",
    "    x = grouped_data.index.categories.left.values\n",
    "    y = grouped_data['mean'].values\n",
    "    \n",
    "    y_err = grouped_data['error_on_the_mean'].values\n",
    "    \n",
    "    ax.plot(x, y)\n",
    "    ax.fill_between(x, y - y_err, y + y_err, alpha=0.2)\n",
    "    ax.set_xlim(0, 1)\n",
    "    \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ca6f6eb26cbed8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "market = 'UW'\n",
    "vol_limit = 0.5\n",
    "\n",
    "fig, axs = plt.subplots(3, 5, figsize=(12, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "selected_tables = f.list_database_tables(DATABASE)[:15]\n",
    "\n",
    "for i, table_name in enumerate(selected_tables):\n",
    "    \n",
    "    ax = axs[i]\n",
    "    \n",
    "    df = pd.read_sql_query(f'SELECT * from {table_name[0]}', conn)\n",
    "    df = df.query('Volatility < @vol_limit and Market == @market')\n",
    "    \n",
    "    grouped_data = select_bins(df)\n",
    "    print(len(grouped_data))\n",
    "    \n",
    "    x = grouped_data.index.categories.left.values\n",
    "    y = grouped_data['mean'].values\n",
    "    \n",
    "    y_err = grouped_data['error_on_the_mean'].values\n",
    "    \n",
    "    ax.plot(x, y)\n",
    "    ax.fill_between(x, y - y_err, y + y_err, alpha=0.2)\n",
    "    \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b0dfa467d2945f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "20373a0287d9a1e9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
