{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MFHT Rolling Windows Plot\n",
    "plt.close('all')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c44dddebf3abc6cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "from stabilvol.utility import functions as f\n",
    "\n",
    "DATABASE = '../data/processed/trapezoidal_selection/stabilvol.sqlite'\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(DATABASE)\n",
    "cur = conn.cursor()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1674e86e0f257dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.path.exists(DATABASE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "862facc766c4eaa8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MARKETS = [\"UN\", \"UW\", \"LN\", \"JT\"]\n",
    "START_DATE = \"1980-01-01\"\n",
    "END_DATE = \"2022-07-01\"\n",
    "\n",
    "START_LEVELS = [-2.0, -1.0, -0.5, -0.2, -0.1, 0.1, 0.2, 0.5, 1.0, 2.0]\n",
    "DELTAS = [2.0, 1.0, 0.5, 0.2, 0.1, -0.1, -0.2, -0.5, -1.0, -2.0]\n",
    "LEVELS = {\n",
    "    (start, round(start+delta, 2)) for start in START_LEVELS for delta in DELTAS\n",
    "}\n",
    "LEVELS = sorted(LEVELS)\n",
    "\n",
    "VOL_LIMIT= 0.5  # Change this will change all the pickle files, remember to re-generate them"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82bc80ada8b46388"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def select_bins(df, max_n=1000):\n",
    "    nbins = 25\n",
    "    \n",
    "    while True:\n",
    "        # Use qcut to bin 'Volatility' values\n",
    "        df['Bins'] = pd.qcut(df['Volatility'], nbins, duplicates='drop')\n",
    "        \n",
    "        # Group by the bins and calculate the mean and standard error of 'value'\n",
    "        grouped = df.groupby('Bins')['FHT'].agg(['mean', error_on_the_mean, 'size'])\n",
    "        count = grouped['size'].min()\n",
    "        \n",
    "        if count < max_n or nbins > 1000:\n",
    "            break\n",
    "        else:\n",
    "            nbins += 20\n",
    "    return grouped, nbins\n",
    "\n",
    "def error_on_the_mean(values):\n",
    "    return np.std(values)/np.sqrt(len(values))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88d2fb62bcaeaccf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def query_binned_data(market: str, start_date:str, end_date:str = None, vol_limit:float = 0.5, t1_string:str = \"m0p5\", t2_string:str = \"m1p5\"):\n",
    "    grouped_data = None\n",
    "    end_date = '2023-01-01' if end_date is None else end_date\n",
    "    try:            \n",
    "        # Write the SQL query\n",
    "        query = f'''\n",
    "        SELECT *\n",
    "        FROM stabilvol_{t1_string}_{t2_string}\n",
    "        WHERE Volatility < {vol_limit} \n",
    "        AND Market = \"{market}\"\n",
    "        AND start >= \"{start_date}\"\n",
    "        AND end <= \"{end_date}\"    \n",
    "        '''\n",
    "        # Load the FHT data from the database\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "    except pd.errors.DatabaseError:\n",
    "        print(f'No data for market {market} with thresholds {t1_string}-{t2_string}')\n",
    "        nbins = 0\n",
    "    else:\n",
    "        if len(df) > 50:\n",
    "            return  select_bins(df)\n",
    "        else:\n",
    "            raise ValueError(f'Not enough data for market {market} with thresholds {t1_string}-{t2_string} from {start_date} to {end_date}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e3d85c019d3aa83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_dataset(windows, t1_string, t2_string):\n",
    "    outcasts = {market: [] for market in MARKETS}\n",
    "    df = pd.DataFrame()\n",
    "    for market in MARKETS:\n",
    "        for start_date, end_date in tqdm(windows, desc=market):\n",
    "            try:\n",
    "                mfht, nbins = query_binned_data(market, start_date, end_date, VOL_LIMIT, t1_string=t1_string, t2_string=t2_string)         \n",
    "            except ValueError:\n",
    "                outcasts[market].append((start_date, end_date))\n",
    "            else:\n",
    "                mfht['start'] = start_date\n",
    "                mfht['end'] = end_date\n",
    "                mfht['market'] = market\n",
    "                df = pd.concat([df, mfht.reset_index()])\n",
    "                \n",
    "    return df, outcasts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59184695ac0cefb6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rolling Windows"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c144d9dd5cb4c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def roll_windows(duration=90,  start_date=None, end_date=None):\n",
    "    # Define the start and end dates\n",
    "    start_date = datetime.date(1980, 1, 1) if start_date is None else start_date\n",
    "    end_date = datetime.date(2022, 7, 1) if end_date is None else end_date\n",
    "    \n",
    "    start = start_date + pd.to_timedelta(duration/2, 'D')\n",
    "    end = end_date - pd.to_timedelta(duration/2, 'D')\n",
    "    return [(mid - pd.to_timedelta(duration//2, 'D'), mid + pd.to_timedelta(duration//2, 'D')) for mid in pd.date_range(start, end, freq='D')]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d719cabbead45107"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "windows = roll_windows(90, start_date=datetime.date(1980, 1, 1), end_date=datetime.date(2023, 1, 1))\n",
    "len(windows)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46a44323cfea3bf2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t1_string = \"m0p5\"\n",
    "t2_string = \"m1p5\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0471ab9f498531c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regenerate = False\n",
    "if not os.path.exists(f'../data/processed/dynamics/rolling_MFHT_peaks_{t1_string}_{t2_string}_{VOL_LIMIT}.npy') or regenerate:\n",
    "    # Data must be regenerate\n",
    "    df, outcasts = create_dataset(windows, t1_string, t2_string)\n",
    "    print(f\"There are {len(outcasts)} outcasts\")\n",
    "    print(outcasts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "171d997b92fc2585"
  },
  {
   "cell_type": "markdown",
   "source": [
    "It may be better to first save peaks data and then plot them"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c5589c6e851ed46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(f'../data/processed/dynamics/rolling_MFHT_peaks_{t1_string}_{t2_string}_{VOL_LIMIT}.npy') or regenerate:\n",
    "    data = df.copy()\n",
    "    max_values = np.zeros((len(MARKETS), len(windows)))\n",
    "    for i, market in enumerate(MARKETS):\n",
    "            for j, (start_date, end_date) in tqdm(enumerate(windows), desc=market):\n",
    "    \n",
    "                mfht = data[(data['market'] == market) & (data['start'] == start_date) & (data['end'] == end_date)]       \n",
    "                if not mfht.empty:            \n",
    "                    max_values[i, j] = mfht['mean'].max()\n",
    "                    \n",
    "    np.save(f'../data/processed/dynamics/rolling_MFHT_peaks_{t1_string}_{t2_string}_{VOL_LIMIT}.npy', max_values)\n",
    "else:\n",
    "    max_values = np.load(f'../data/processed/dynamics/rolling_MFHT_peaks_{t1_string}_{t2_string}_{VOL_LIMIT}.npy')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b07a5fd60f2c9dc4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = datetime.date(1980,1,1)\n",
    "end = datetime.date(2023,1,1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c73532c7bd47b85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_quarters(start_date, end_date, freq='Q'):\n",
    "    # Generate all quarters between start and end date\n",
    "    quarters = list(pd.date_range(start_date, end_date, freq=freq))\n",
    "    if quarters[0].date() > start_date.date():\n",
    "        quarters.insert(0, start_date)\n",
    "    if quarters[-1].date() < end_date.date():\n",
    "        quarters.append(pd.to_datetime(end_date))\n",
    "\n",
    "    return pd.to_datetime(quarters)\n",
    "\n",
    "\n",
    "def add_ticks(ax, windows, market, outcasts, highlights=True):\n",
    "    labels = [end_date.strftime('%Y-%m-%d') for start_date, end_date in windows]\n",
    "    label_dates = pd.to_datetime(labels)\n",
    "    quarters = generate_quarters(label_dates[0], label_dates[-1], 'Y')\n",
    "    tick_coords = np.array([np.where(label_dates == date)[0][0] for date in quarters[1:-1]])\n",
    "    ax.set_xticks(tick_coords-1, labels=[labels[j] for j in tick_coords], minor=False, \n",
    "                  fontsize=11, rotation=90, rotation_mode='anchor', ha='right', va='center_baseline')\n",
    "    ax.set_ylabel(market, fontsize=16)\n",
    "    # Remove yticks\n",
    "    ax.yaxis.set_ticks([])\n",
    "    \n",
    "    # Convert labels to Timestamps\n",
    "    label_dates = pd.to_datetime(labels)\n",
    "    outcast_dates = [(pd.to_datetime(start), pd.to_datetime(end)) for start, end in outcasts]\n",
    "    for outcast in outcast_dates:\n",
    "        # Find the indices of the start and end labels\n",
    "        start_index = np.where(label_dates <= outcast[0])\n",
    "        # Since only the end date is labeled, if the first start date is an outcast, it must be set manually\n",
    "        start_index = start_index[0][-1] if len(start_index[0]) > 0 else 0\n",
    "        end_index = np.where(label_dates >= outcast[1])[0][0]\n",
    "        ax.axvspan(start_index-0.5, end_index-0.5, color='black')\n",
    "    \n",
    "    if highlights:\n",
    "        # Find the indices of the start and end labels\n",
    "        start_index = np.where(label_dates < pd.to_datetime('2006-12-31'))[0][-1]\n",
    "        end_index = np.where(label_dates > pd.to_datetime('2008-12-31'))[0][0]\n",
    "    \n",
    "        # Add vertical lines at the start and end of the region\n",
    "        ax.axvline(start_index, color='k', linestyle='--', linewidth=1.5)\n",
    "        ax.axvline(end_index, color='k', linestyle='--', linewidth=1.5)\n",
    "\n",
    "\n",
    "def plot_rolling_heatmap(windows, maxs=None, outcasts=None, **kwargs):\n",
    "    toosmallwindows = 0\n",
    "    if outcasts is None:\n",
    "        outcasts = {market: [] for market in MARKETS}\n",
    "        search_outcasts = True\n",
    "    else:\n",
    "        search_outcasts = False\n",
    "    if kwargs.get('latex', False):    \n",
    "        # Use LaTeX for text rendering\n",
    "        plt.rcParams['text.usetex'] = True\n",
    "        plt.rcParams['font.family'] = 'serif'\n",
    "    \n",
    "    fig, axs = plt.subplots(4, figsize=(12, 4), sharex=True)\n",
    "    \n",
    "    max_values = np.zeros((len(MARKETS), len(windows))) if maxs is None else maxs\n",
    "    \n",
    "\n",
    "    for i, (market, ax) in enumerate(zip(MARKETS, axs.flatten())):\n",
    "        for j, (start_date, end_date) in enumerate(windows):\n",
    "            if maxs is None:\n",
    "                # Calculate the peaks\n",
    "                mfht = data[(data['market'] == market) & (data['start'] == start_date) & (data['end'] == end_date)]       \n",
    "                if mfht.empty:            \n",
    "                    outcasts[market].append((start_date, end_date))\n",
    "                else:\n",
    "                    max_values[i, j] = mfht['mean'].max()\n",
    "            elif search_outcasts:\n",
    "                # See where the max is zero and label it as outcast\n",
    "                if max_values[i, j] == 0:\n",
    "                    outcasts[market].append((start_date, end_date))\n",
    "                \n",
    "\n",
    "        im = ax.imshow(max_values[i].reshape(1, -1), cmap='coolwarm', aspect='auto', vmin=max_values[i].min(), vmax=max_values[i].max())\n",
    "         # Show ticks four by four and label them with the respective list entries\n",
    "        add_ticks(ax, windows, market, outcasts[market])\n",
    "    \n",
    "    # axs[0].text(0.57, 1.1, '2006-12-31', fontsize=11, transform=axs[0].transAxes, horizontalalignment='left')\n",
    "    # axs[0].text(0.73, 1.1, '2008-12-31', fontsize=11, transform=axs[0].transAxes, horizontalalignment='right')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Add a colorbar\n",
    "    cbar = fig.colorbar(im, ax=axs.ravel().tolist(), pad=0.01)\n",
    "    cbar.set_label('Maximum MFHT', rotation=270, labelpad=15)\n",
    "\n",
    "    plt.show()\n",
    "    return fig, toosmallwindows"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ce2cb8a05e10556"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, errors = plot_rolling_heatmap(windows, max_values, outcasts if regenerate else None, latex=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29aab472b5884f6e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.savefig(f'../visualization/dynamics/rolling_windows/rolling_MFHT_peaks_{t1_string}_{t2_string}_{VOL_LIMIT}.png', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/rolling_MFHT_peaks_{t1_string}_{t2_string}_{VOL_LIMIT}.eps', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/rolling_MFHT_peaks_{ t1_string}_{t2_string}_{VOL_LIMIT}.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6089305ab007ab4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def take_maxs(df, t1_string, t2_string, windows, regenerate=False):\n",
    "    if not os.path.exists(f'../data/processed/dynamics/rolling_MFHT_peaks_{t1_string}_{t2_string}_{VOL_LIMIT}.npy') or regenerate:  \n",
    "        data = df.copy()\n",
    "        max_values = np.zeros((len(MARKETS), len(windows)))\n",
    "        for i, market in enumerate(MARKETS):\n",
    "                for j, (start_date, end_date) in tqdm(enumerate(windows), desc=market):\n",
    "        \n",
    "                    mfht = data[(data['market'] == market) & (data['start'] == start_date) & (data['end'] == end_date)]       \n",
    "                    if not mfht.empty:            \n",
    "                        max_values[i, j] = mfht['mean'].max()\n",
    "                        \n",
    "        np.save(f'../data/processed/dynamics/rolling_MFHT_peaks_{t1_string}_{t2_string}_{VOL_LIMIT}.npy', max_values)\n",
    "    else:\n",
    "        max_values = np.load(f'../data/processed/dynamics/rolling_MFHT_peaks_{t1_string}_{t2_string}_{VOL_LIMIT}.npy')\n",
    "    return max_values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7872efbd0f5354e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rallies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92e1d5e6ecfd1ef2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we consider rallies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "675f56860c8356d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t1_string = \"1p0\"\n",
    "t2_string = \"1p5\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23ecadec09738d07"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regenerate = False\n",
    "if not os.path.exists(f'../data/processed/dynamics/rolling_MFHT_peaks_{t1_string}_{t2_string}_{VOL_LIMIT}.npy') or regenerate:\n",
    "    df, outcasts = create_dataset(windows, t1_string=t1_string, t2_string=t2_string)\n",
    "    print(f\"There are {len(outcasts)} outcasts\") \n",
    "    outcasts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21c355ce040ff98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_values = take_maxs(df, t1_string, t2_string, windows, regenerate=regenerate)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dd56faaddf622d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, errors = plot_rolling_heatmap(windows, max_values, outcasts if regenerate else None, latex=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3acf398e7d839e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.savefig(f'../visualization/dynamics/rolling_windows/rolling_MFHT_peaks_{t1_string}_{t2_string}.png', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/rolling_MFHT_peaks_{t1_string}_{t2_string}.eps', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/rolling_MFHT_peaks_{t1_string}_{t2_string}.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e3ec5c3473acfec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More Plots"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f268151fad1608a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we change the thresholds to see if something relevant changes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "754a21988a601b4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Crash\n",
    "crash_thresholds2 = (\"m2p0\", \"m2p2\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "587750ed3ea39725"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regenerate = False\n",
    "if not os.path.exists(f'../data/processed/dynamics/rolling_MFHT_peaks_{crash_thresholds2[0]}_{crash_thresholds2[1]}_{VOL_LIMIT}.npy') or regenerate:\n",
    "    df, outcasts = create_dataset(windows, t1_string=crash_thresholds2[0], t2_string=crash_thresholds2[1])\n",
    "    print(f\"There are {len(outcasts)} outcasts\")\n",
    "    outcasts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90c0be7f9f8c19a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_values = take_maxs(df, crash_thresholds2[0], crash_thresholds2[1], windows, regenerate=regenerate)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb5d31acb428498f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, errors = plot_rolling_heatmap(windows, max_values, outcasts if regenerate else None, latex=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51e1f35d1c08ae1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.savefig(f'../visualization/dynamics/rolling_windows/rolling_MFHT_peaks_{crash_thresholds2[0]}_{crash_thresholds2[1]}.png', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/rolling_MFHT_peaks_{crash_thresholds2[0]}_{crash_thresholds2[1]}.eps', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/rolling_MFHT_peaks_{crash_thresholds2[0]}_{crash_thresholds2[1]}.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73a48e78bcfa5987"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rally\n",
    "rally_thresholds2 = (\"2p0\", \"2p2\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "522f30fa4e0c8e57"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regenerate = False\n",
    "if not os.path.exists(f'../data/processed/dynamics/rolling_MFHT_peaks_{rally_thresholds2[0]}_{rally_thresholds2[1]}_{VOL_LIMIT}.npy') or regenerate:\n",
    "    df, outcasts = create_dataset(windows, t1_string=rally_thresholds2[0], t2_string=rally_thresholds2[1])\n",
    "    print(f\"There are {len(outcasts)} outcasts\")\n",
    "    outcasts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d474e457066218b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_values = take_maxs(df, rally_thresholds2[0], rally_thresholds2[1], windows, regenerate=regenerate)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1140b1d9abd58ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, errors = plot_rolling_heatmap(windows, max_values, outcasts if regenerate else None, latex=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "174b65a51dd74071"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.savefig(f'../visualization/dynamics/rolling_windows/rolling_MFHT_peaks_{rally_thresholds2[0]}_{rally_thresholds2[1]}.png', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/rolling_MFHT_peaks_{rally_thresholds2[0]}_{rally_thresholds2[1]}.eps', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/rolling_MFHT_peaks_{rally_thresholds2[0]}_{rally_thresholds2[1]}.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1b13756dac5e142"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7e13650dfbf3474"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
