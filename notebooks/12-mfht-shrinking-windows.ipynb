{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "aa# MFHT Grid Plot\n",
    "plt.close('all')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c44dddebf3abc6cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "from stabilvol.utility import functions as f\n",
    "\n",
    "DATABASE = '../data/processed/trapezoidal_selection/stabilvol.sqlite'\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(DATABASE)\n",
    "cur = conn.cursor()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1674e86e0f257dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.path.exists(DATABASE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "862facc766c4eaa8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def select_bins(df, max_n=1000):\n",
    "    nbins = 50\n",
    "    \n",
    "    while True:\n",
    "        # Use qcut to bin 'Volatility' values\n",
    "        df['Bins'] = pd.qcut(df['Volatility'], nbins, duplicates='drop')\n",
    "        \n",
    "        # Group by the bins and calculate the mean and standard error of 'value'\n",
    "        grouped = df.groupby('Bins')['FHT'].agg(['mean', error_on_the_mean, 'size'])\n",
    "        count = grouped['size'].min()\n",
    "        \n",
    "        if count < max_n or nbins > 1000:\n",
    "            break\n",
    "        else:\n",
    "            nbins += 20\n",
    "    return grouped, nbins\n",
    "\n",
    "def error_on_the_mean(values):\n",
    "    return np.std(values)/np.sqrt(len(values))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88d2fb62bcaeaccf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MARKETS = [\"UN\", \"UW\", \"LN\", \"JT\"]\n",
    "START_DATE = \"1980-01-01\"\n",
    "END_DATE = \"2022-07-01\"\n",
    "START_LEVELS = [-2.0, -1.0, -0.5, -0.2, -0.1, 0.1, 0.2, 0.5, 1.0, 2.0]\n",
    "DELTAS = [2.0, 1.0, 0.5, 0.2, 0.1, -0.1, -0.2, -0.5, -1.0, -2.0]\n",
    "LEVELS = {\n",
    "    (start, round(start+delta, 2)) for start in START_LEVELS for delta in DELTAS\n",
    "}\n",
    "LEVELS = sorted(LEVELS)\n",
    "\n",
    "VOL_LIMIT= 0.5  # Change this will change all the pickle files, remember to re-generate them\n",
    "LEVELS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "806e9dff7eb02a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def query_binned_data(market: str, start_date:str, end_date:str = None, vol_limit:float = 0.5, t1_string:str = \"m0p5\", t2_string:str = \"m1p5\"):\n",
    "    grouped_data = None\n",
    "    end_date = '2022-07-01' if end_date is None else end_date\n",
    "    try:            \n",
    "        # Write the SQL query\n",
    "        query = f'''\n",
    "        SELECT *\n",
    "        FROM stabilvol_{t1_string}_{t2_string}\n",
    "        WHERE Volatility < {vol_limit} \n",
    "        AND Market = \"{market}\"\n",
    "        AND start > \"{start_date}\"\n",
    "        AND end < \"{end_date}\"    \n",
    "        '''\n",
    "        # Load the FHT data from the database\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "    except pd.errors.DatabaseError:\n",
    "        print(f'No data for market {market} with thresholds {t1_string}-{t2_string}')\n",
    "        nbins = 0\n",
    "    else:\n",
    "        grouped_data, nbins = select_bins(df)\n",
    "    return grouped_data, nbins\n",
    "\n",
    "def save_all_mfhts(market, save=True):\n",
    "    bins_dict = {}\n",
    "    for t1, t2 in tqdm(LEVELS):\n",
    "        # Create the strings for the threshold values\n",
    "        t1_string = f.stringify_threshold(t1)\n",
    "        t2_string = f.stringify_threshold(t2)\n",
    "        # Filename for the MFHT data\n",
    "        filename = f'../data/processed/trapezoidal_selection/mfht_{market}_{t1_string}_{t2_string}.pkl'\n",
    "           \n",
    "        if save and not os.path.exists(filename):\n",
    "            # Load the dataframe from the database if it exists\n",
    "            grouped_data, nbins = query_binned_data(market, t1_string, t2_string, VOL_LIMIT)\n",
    "            grouped_data.to_pickle(filename)\n",
    "        else:\n",
    "            print(f\"File '{filename}' already exists\")\n",
    "            nbins = 0\n",
    "        bins_dict[(t1, t2)] = nbins  \n",
    "            \n",
    "    return bins_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e3d85c019d3aa83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df, _ = query_binned_data(\"UN\", \"2000-10-01\", \"2022-01-01\", 0.5)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8020cd9520f4f5ee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shrinking Window\n",
    "We take the start date closer to the end date to see if the nonmonotic behaviour vanishes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89c5172728c54360"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_dates():\n",
    "    # Define the start and end dates\n",
    "    start_date = datetime.date(1980, 1, 1)\n",
    "    end_date = datetime.date(2022, 6, 25)\n",
    "    \n",
    "    # Calculate the number of days between the start and end dates\n",
    "    total_days = (end_date - start_date).days\n",
    "    \n",
    "    # Generate a logarithmically spaced sequence of numbers between 1 and the total number of days\n",
    "    log_days = np.logspace(0, np.log10(total_days), num=21, base=10.0)\n",
    "    # Convert to integers to remove duplicates, then sort\n",
    "    log_days = sorted(set(map(int, log_days)), reverse=True)\n",
    "    \n",
    "    # Convert the logarithmically spaced numbers to dates\n",
    "    return [end_date - datetime.timedelta(days=int(d)) for d in log_days]\n",
    "    \n",
    "dates = create_dates()\n",
    "print(f\"There are {len(dates)} dates starting from {dates[0]} to {dates[-1]}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c4da850bbd7cdd3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def desaturate_color(color):\n",
    "    # Convert RGB to HLS\n",
    "    rgb = mcolors.to_rgb(color)\n",
    "    h, s, v = mcolors.rgb_to_hsv(rgb)\n",
    "\n",
    "    # Decrease the saturation by 50% to get a desaturated color\n",
    "    return mcolors.hsv_to_rgb((h, s/4, v))\n",
    "\n",
    "\n",
    "def plot_mfhts(market, mfht, ax, **kwargs):\n",
    "    x = mfht.index.categories.left.values\n",
    "    # Renormalize the first value\n",
    "    x[0] = 0\n",
    "    y = mfht['mean'].values\n",
    "    \n",
    "    line, = ax.plot(x, y, label=kwargs.get('label', None))\n",
    "    \n",
    "    if kwargs.get('error', True):\n",
    "        y_err = mfht['error_on_the_mean'].values     \n",
    "        ax.fill_between(x, y - y_err, y + y_err, color=desaturate_color(line.get_color()))\n",
    "\n",
    "    ax.set_title(r\"\\emph{\" + market + r\"}\", fontsize=18)\n",
    "    \n",
    "    ax.set_xlim(kwargs.get('xlim', (-0.001, 0.08)))\n",
    "    \n",
    "    ax.set_yscale(kwargs.get('yscale', 'linear'))\n",
    "    \n",
    "    ax.grid(True)\n",
    "    return ax\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "def plot_inset(mfht, inset_ax):\n",
    "    mfht.dropna(inplace=True)    \n",
    "    x = [cat.left for cat in mfht.index.tolist()]\n",
    "    y = mfht['mean'].values\n",
    "    \n",
    "    # Now you can plot on the inset axes\n",
    "    inset_ax.plot(x, y)\n",
    "    return inset_ax"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "604e6a1bd88b5f4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use LaTeX for text rendering\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8), sharey=True, sharex=True)\n",
    "\n",
    "axs[0, 0].set_ylabel('MFHT', y=-0.1 ,fontsize=16)\n",
    "axs[1, 0].set_xlabel('Volatility', x=1.1, fontsize=16)\n",
    "\n",
    "for i, (market, ax) in enumerate(zip(MARKETS, axs.flatten())):\n",
    "    # Place the inset axes\n",
    "    inset_ax = inset_axes(ax, width=\"50%\", height=\"60%\", loc=1) \n",
    "    inset_ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "    for start_date in tqdm(dates, desc=market):\n",
    "        mfht, nbins = query_binned_data(market, start_date, VOL_LIMIT)\n",
    "        \n",
    "        ax = plot_mfhts(market, mfht, ax)\n",
    "        \n",
    "        if start_date in dates[-10:-1]:\n",
    "            inset_ax = plot_inset(mfht, inset_ax)\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "518cfeb98a42759b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.savefig(f'../visualization/dynamics/shrinking_windows.png', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/shrinking_windows.eps', bbox_inches='tight', dpi=300)\n",
    "fig.savefig(f'../visualization/dynamics/shrinking_windows.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40fb90c5fc165175"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Focus on the last shorter windows"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12b6813177ed7ef2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "market = \"UN\"\n",
    "# Assuming 'ax' is your existing axes object\n",
    "inset_ax = inset_axes(ax, width=\"50%\", height=\"60%\", loc=1)  # loc parameter is the location of the inset axes\n",
    "# You may also want to adjust the ticks\n",
    "inset_ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "for start_date in dates:\n",
    "        mfht, nbins = query_binned_data(market, start_date, VOL_LIMIT)\n",
    "        print(nbins, end=', ')\n",
    "        ax = plot_mfhts(market, mfht, ax, xlim=(-0.005, 0.08))\n",
    "        \n",
    "        if start_date in dates[-10:-1]:            \n",
    "            plot_inset(mfht, inset_ax)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b17873aaa83f559"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2008 Crisis\n",
    "Please note that we need to establish clear key dates:\n",
    "15th September 2008 bankruptcy filing of LB\n",
    "\\url{https://en.wikipedia.org/wiki/Lehman\\_Brothers}\n",
    "\n",
    "but troubles started much earlier with the subprime mortgage crisis, so we need to look at when housing market prices crashed.\n",
    "\n",
    "Note: \"In August 2007, the firm closed its subprime lender, BNC Mortgage, eliminating 1,200 positions in 23 locations, and took an after-tax charge of \\$25 million and a \\$27 million reduction in goodwill. Lehman said that poor market conditions in the mortgage space \"necessitated a substantial reduction in its resources and capacity in the subprime space.\"\n",
    "\n",
    "In September 2007, Joe Gregory appointed Erin Callan as CFO. On March 16, 2008, after rival Bear Stearns was taken over by JP Morgan Chase in a fire sale, market analysts suggested that Lehman would be the next major investment bank to fall. Callan fielded Lehman's first quarter conference call, where the firm posted a profit of \\$489 million, compared to Citigroup's \\$5.1 billion and Merrill Lynch's \\$1.97 billion losses which was Lehmanâ€™s 55th consecutive profitable quarter. The firm's stock price leapt 46 percent after that announcement.\" \n",
    "\n",
    "Also note that March 2007 marks the beginning of the subprime crisis with the largest drop in house prices in a decade."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7517db5de7f548fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CRISIS2007 = datetime.date(2007, 3, 15)\n",
    "CRISIS2008 = datetime.date(2008, 9, 15)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81b3a6d5c6f6e845"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_dates(center_date, nwindows=20):\n",
    "    # Define the maximum duration (28 years in days)\n",
    "    max_duration = 28 * 365\n",
    "    \n",
    "    # Generate durations that decrease logarithmically\n",
    "    durations = np.logspace(1.4, np.log10(max_duration), num=nwindows, base=10.0)\n",
    "    durations = sorted(set(map(int, durations)), reverse=True)\n",
    "    \n",
    "    # Generate the windows\n",
    "    return [(center_date - datetime.timedelta(days=int(d))/2, center_date + datetime.timedelta(days=int(d))/2) for d in durations]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "558b627c85422be1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_shrinkingmfht(windows, vol_limit = VOL_LIMIT):\n",
    "    # Use LaTeX for text rendering\n",
    "    plt.rcParams['text.usetex'] = True\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 8), sharey=True, sharex=True)\n",
    "    \n",
    "    axs[0, 0].set_ylabel('MFHT', y=-0.1 ,fontsize=16)\n",
    "    axs[1, 0].set_xlabel('Volatility', x=1.1, fontsize=16)\n",
    "    \n",
    "    for i, (market, ax) in enumerate(zip(MARKETS, axs.flatten())):\n",
    "        # Place the inset axes\n",
    "        inset_ax = inset_axes(ax, width=\"50%\", height=\"60%\", loc=1) \n",
    "        inset_ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "        for start_date, end_date in tqdm(windows, desc=market):\n",
    "            duration = end_date - start_date \n",
    "            \n",
    "            mfht, nbins = query_binned_data(market, start_date, end_date, vol_limit)\n",
    "            \n",
    "            ax = plot_mfhts(market, mfht, ax, error=False, label=duration.days)\n",
    "            \n",
    "            if duration < pd.to_timedelta('90d'):\n",
    "                inset_ax = plot_inset(mfht, inset_ax)\n",
    "    \n",
    "    # fig.tight_layout()\n",
    "    # Add common legend on top\n",
    "    handles, labels = axs[0, 0].get_legend_handles_labels()  # get the handles and labels from any subplot\n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=4)  # place the legend outside the plot area\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bc6cda441bea85d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### March 2007"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1802a09aaec7bad2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "windows = create_dates(CRISIS2007, 16)\n",
    "\n",
    "plot_shrinkingmfht(windows)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32c77ee409f101d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### September 2008"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c966e0cccca3473a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "windows = create_dates(CRISIS2008, 16)\n",
    "\n",
    "plot_shrinkingmfht(windows)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80ffc9f91bc3aad9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Before the Crisis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20cb351126c2f341"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nyears = 3 # Number of years before the crisis\n",
    "windows = create_dates(CRISIS2007 - datetime.timedelta(days=nyears*365), 12)\n",
    "\n",
    "plot_shrinkingmfht(windows)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31873c6b667d1d15"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### After the Crisis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2e80d49a68bcfbc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nyears = -3 # Number of years before the crisis\n",
    "windows = create_dates(CRISIS2007 - datetime.timedelta(days=nyears*365), 12)\n",
    "\n",
    "plot_shrinkingmfht(windows)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f92fb8d4686cc21b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apparently nothing important changes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c98554a779233515"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
