{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MFHT Rolling Windows PDF Comparison\n",
    "\n",
    "A day-by-day comparison is hard to look at, there are too little changes.\n",
    "---\n",
    "To do: \n",
    "1) Only accounts for dates where we must reject the null hypothesis (p-value < 0.05) in favour of the alternative (data were drawn from *different* distributions)\n",
    "2) Increase the distance between the windows to compare:\n",
    "    - 28 days *(one month)* ---OK\n",
    "    - 3 months *(one quarter, 90 days)*  ---OK\n",
    "    - 1 year *(365 days)*  ---\n",
    "    - 2 years *(500 days)* "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c44dddebf3abc6cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from scipy.stats import ks_2samp\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from stabilvol.utility import functions as f\n",
    "\n",
    "DATABASE = '../data/processed/trapezoidal_selection/stabilvol.sqlite'\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(DATABASE)\n",
    "cur = conn.cursor()\n",
    "import os\n",
    "print(os.getcwd())\n",
    "os.path.exists(DATABASE)\n",
    "\n",
    "MARKETS = [\"UN\", \"UW\", \"LN\", \"JT\"]\n",
    "START_DATE = \"1980-01-01\"\n",
    "END_DATE = \"2022-07-01\"\n",
    "\n",
    "START_LEVELS = [-2.0, -1.0, -0.5, -0.2, -0.1, 0.1, 0.2, 0.5, 1.0, 2.0]\n",
    "DELTAS = [2.0, 1.0, 0.5, 0.2, 0.1, -0.1, -0.2, -0.5, -1.0, -2.0]\n",
    "LEVELS = {\n",
    "    (start, round(start+delta, 2)) for start in START_LEVELS for delta in DELTAS\n",
    "}\n",
    "LEVELS = sorted(LEVELS)\n",
    "\n",
    "VOL_LIMIT= 0.5  # Change this will change all the pickle files, remember to re-generate them\n",
    "\n",
    "NDAYS = 28"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1674e86e0f257dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def select_bins(df, max_n=1000):\n",
    "    nbins = 200\n",
    "    \n",
    "    while True:\n",
    "        # Use qcut to bin 'Volatility' values\n",
    "        df['Bins'] = pd.qcut(df['Volatility'], nbins, duplicates='drop')\n",
    "        \n",
    "        # Group by the bins and calculate the mean and standard error of 'value' and the number of observations in each bin\n",
    "        grouped = df.groupby('Bins')['FHT'].agg(['mean', 'size'])\n",
    "        # Take the lowest count of observations in the bins\n",
    "        count = grouped['size'].min()\n",
    "        \n",
    "        if count < max_n or nbins > 1000:\n",
    "            break\n",
    "        else: \n",
    "            nbins += 100\n",
    "    return grouped, nbins\n",
    "\n",
    "def error_on_the_mean(values):\n",
    "    return np.std(values)/np.sqrt(len(values))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88d2fb62bcaeaccf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def query_binned_data(market: str, start_date:str, end_date:str = None, vol_limit:float = 0.5, t1_string:str = \"m0p5\", t2_string:str = \"m1p5\"):\n",
    "    grouped_data = None\n",
    "    end_date = '2023-01-01' if end_date is None else end_date\n",
    "    try:            \n",
    "        # Write the SQL query\n",
    "        query = f'''\n",
    "        SELECT *\n",
    "        FROM stabilvol_{t1_string}_{t2_string}\n",
    "        WHERE Volatility < {vol_limit} \n",
    "        AND Market = \"{market}\"\n",
    "        AND start >= \"{start_date}\"\n",
    "        AND end <= \"{end_date}\"    \n",
    "        '''\n",
    "        # Load the FHT data from the database\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "    except pd.errors.DatabaseError:\n",
    "        print(f'No data for market {market} with thresholds {t1_string}-{t2_string}')\n",
    "        nbins = 0\n",
    "    else:\n",
    "        if len(df) > 50:\n",
    "            return  select_bins(df)\n",
    "        else:\n",
    "            raise ValueError(f'Not enough data for market {market} with thresholds {t1_string}-{t2_string} from {start_date} to {end_date}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e3d85c019d3aa83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_dataset_old(markets, windows, t1_string, t2_string, vol_limit=VOL_LIMIT):\n",
    "    outcasts = {market: [] for market in markets}\n",
    "    df_list = list()\n",
    "    for market in markets:\n",
    "        for start_date, end_date in tqdm(windows, desc=market):\n",
    "            try:\n",
    "                mfht, nbins = query_binned_data(market, start_date, end_date, vol_limit, t1_string=t1_string, t2_string=t2_string)         \n",
    "            except ValueError:\n",
    "                outcasts[market].append((start_date, end_date))\n",
    "            else:\n",
    "                mfht['start'] = start_date\n",
    "                mfht['end'] = end_date\n",
    "                mfht['market'] = market\n",
    "                df_list.append(mfht.reset_index())\n",
    "                \n",
    "    return pd.concat(df_list), outcasts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59184695ac0cefb6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, current_process\n",
    "\n",
    "def process_market_window(args):\n",
    "    print(f\"Processing {args} on process id {current_process().pid}\")\n",
    "    market, window, t1_string, t2_string = args\n",
    "    try:\n",
    "        mfht, nbins = query_binned_data(market, *window, vol_limit=VOL_LIMIT, t1_string=t1_string, t2_string=t2_string)\n",
    "    except ValueError:\n",
    "        return (market, window)\n",
    "    else:\n",
    "        mfht['start'] = window[0]\n",
    "        mfht['end'] = window[1]\n",
    "        mfht['market'] = market\n",
    "        return mfht.reset_index()\n",
    "\n",
    "def create_dataset(markets, windows, t1_string, t2_string, vol_limit=VOL_LIMIT):\n",
    "    outcasts = {market: [] for market in markets}\n",
    "    df_list = list()\n",
    "\n",
    "    with Pool(processes=10) as pool:\n",
    "        args = [(market, window, t1_string, t2_string) for market in markets for window in windows]\n",
    "        results = pool.map(process_market_window, args)\n",
    "\n",
    "    for result in results:\n",
    "        if isinstance(result, pd.DataFrame):\n",
    "            df_list.append(result)\n",
    "        else:\n",
    "            market, window = result\n",
    "            outcasts[market].append(window)\n",
    "\n",
    "    return pd.concat(df_list), outcasts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43aab0f5454f5f7c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_mfhts(market, windows, ndays, coefficients, regenerate=False):\n",
    "    \"\"\"\n",
    "    Perform a KS-test on the MFHT of one window against that shifted ndays later.\n",
    "    \"\"\"\n",
    "    outcasts = {coeff: [] for coeff in coefficients}\n",
    "    if not regenerate:\n",
    "        # Load the p-values and statistics values of the KS-test\n",
    "        p_values = np.load(f'../data/processed/kstest/{market}_rolling_MFHT_p_variousthresholds_{VOL_LIMIT}.npy')\n",
    "        stats_values = np.load(f'../data/processed/kstest/{market}_rolling_MFHT_stats_variousthresholds_{VOL_LIMIT}.npy')\n",
    "    else:\n",
    "        # Alllocate space for the p-values and statistics values of the KS-test\n",
    "        p_values = np.zeros((len(coefficients), len(windows))) - 1\n",
    "        stats_values = np.zeros((len(coefficients), len(windows))) - 1\n",
    "        \n",
    "        for i, (t1_string, t2_string) in enumerate(coefficients):\n",
    "            # Load data for given thresholds\n",
    "            df = pd.read_pickle(f'../data/processed/dynamics/{market}_rolling_MFHT_peaks_{t1_string}_{t2_string}_200bins_{VOL_LIMIT}.pickle')\n",
    "\n",
    "            for j, (start_date, end_date) in enumerate(tqdm(windows, desc=market)):\n",
    "                # Take the MFHT at the current window and the shifted one\n",
    "                mfht = df[(df['start'] == start_date) & (df['end'] == end_date)]['mean']\n",
    "                try:\n",
    "                    next_start, next_end = windows[j + ndays]\n",
    "                except IndexError:\n",
    "                    print(f\"Out of range for {start_date} and {end_date}\")\n",
    "                    break\n",
    "                else:\n",
    "                    mfht_next = df[(df['start'] == next_start) & (df['end'] == next_end)]['mean']\n",
    "                    \n",
    "                # Perform the KS-test\n",
    "                if not mfht.empty and not mfht_next.empty:\n",
    "                    p_values[i, j] = ks_2samp(mfht, mfht_next).pvalue\n",
    "                    stats_values[i, j] = ks_2samp(mfht, mfht_next).statistic\n",
    "                else:\n",
    "                    outcasts[(t1_string, t2_string)].append((start_date, end_date))\n",
    "\n",
    "        # Save the p-values and statistics values of the KS-tests\n",
    "        np.save(f'../data/processed/kstest/{market}_rolling_MFHT_stats_variousthresholds_{VOL_LIMIT}.npy', stats_values)\n",
    "        np.save(f'../data/processed/kstest/{market}_rolling_MFHT_p_variousthresholds_{VOL_LIMIT}.npy', p_values)\n",
    "    return p_values, stats_values, outcasts\n",
    "\n",
    "\n",
    "def print_rejections(p_values, windows, ndays, coefficients,):\n",
    "    # Resample windows\n",
    "    windows = [windows[i] for i in range(0, len(windows), ndays)]\n",
    "    # Print the rejection (max 100) \n",
    "    for i, (coeff) in enumerate(coefficients):\n",
    "        max_print = 0\n",
    "        for j, (start_date, end_date) in enumerate(windows[1:]):\n",
    "            if max_print > 100:\n",
    "                break\n",
    "            if 0.05 >= p_values[i, j] > 0:\n",
    "                print(f\"Reject ({start_date.date()}/{end_date.date()}) p-value {p_values[i, j]}\")\n",
    "                max_print += 1\n",
    "        print(f\"There were {max_print} rejections for {coeff}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9228e1548d39044e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_quarters(start_date, end_date, freq='Q'):\n",
    "    # Generate all quarters between start and end date\n",
    "    quarters = list(pd.date_range(start_date, end_date, freq=freq))\n",
    "    if quarters[0].date() > start_date.date():\n",
    "        quarters.insert(0, start_date)\n",
    "    if quarters[-1].date() < end_date.date():\n",
    "        quarters.append(pd.to_datetime(end_date))\n",
    "\n",
    "    return pd.to_datetime(quarters)\n",
    "\n",
    "\n",
    "def add_ticks(ax, windows, coeff, outcasts, highlights=True, **kwargs):\n",
    "    ax.set_title(' '.join([r'$\\theta_i$=', f.numerify_threshold(coeff[0]), r'/ $\\theta_f$=', f.numerify_threshold(coeff[1])]), fontsize=12)\n",
    "    # Remove yticks\n",
    "    ax.yaxis.set_ticks([])\n",
    "    \n",
    "    \n",
    "    if NDAYS != 1:\n",
    "        # Set the xticks to be the start date of each window\n",
    "        label_spacing = kwargs.get('label_spacing', 1)\n",
    "        labels = [win[0].strftime('%Y-%b') for win in windows][::label_spacing]\n",
    "        l = 1\n",
    "        # Add the last date\n",
    "        labels.append(windows[-1][1].strftime('%Y-%b'))\n",
    "        if len(labels) != len(np.arange(0, len(windows) + l, label_spacing)):\n",
    "            # Add last window end\n",
    "            l += label_spacing\n",
    "        ax.set_xticks(np.arange(0, len(windows) + l, label_spacing))\n",
    "        ax.set_xticklabels(labels, rotation=90, va='bottom', fontsize=11, y=-0.9)\n",
    "        ax.tick_params(axis='x', colors='black', direction='out', length=6, width=2)\n",
    "        \n",
    "    else:\n",
    "        print(\"Come back to the heatmap plot\")\n",
    "        return None\n",
    "    \n",
    "    label_dates = [start_date for start_date, end_date in windows]\n",
    "    label_dates.append(windows[-1][1])\n",
    "    label_dates = pd.to_datetime(label_dates)\n",
    "    outcast_dates = [(pd.to_datetime(start), pd.to_datetime(end)) for start, end in outcasts]\n",
    "    for outcast in outcast_dates:\n",
    "        # Find the indices of the start and end labels\n",
    "        try:\n",
    "            start_index = np.where(label_dates <= outcast[0])\n",
    "            # Since only the end date is labeled, if the first start date is an outcast, it must be set manually\n",
    "            start_index = start_index[0][-1] if len(start_index[0]) > 0 else 0\n",
    "            end_index = np.where(label_dates >= outcast[1])[0][0]\n",
    "        except IndexError as e:\n",
    "            print(f'Cannot find end index for date {outcast[1]}')\n",
    "        else:\n",
    "            ax.axvspan(start_index, end_index, color='black')\n",
    "    \n",
    "    if highlights:\n",
    "        try:\n",
    "            # Find the indices of the start and end labels\n",
    "            start_index = np.where(label_dates < pd.to_datetime('2006-12-31'))[0][-1]\n",
    "            end_index = np.where(label_dates > pd.to_datetime('2008-12-31'))[0][0]\n",
    "        except IndexError as e:\n",
    "            print(f'Cannot highlight crisis: ', e)\n",
    "        finally:\n",
    "            # Add vertical lines at the start and end of the region\n",
    "            ax.axvline(start_index, color='k', linestyle='--', linewidth=1.5)\n",
    "            ax.axvline(end_index, color='k', linestyle='--', linewidth=1.5)\n",
    "\n",
    "\n",
    "def plot_rolling_pmesh(coefficients, windows, values, **kwargs):\n",
    "    outcasts = {(t1, t2): [] for t1, t2 in coefficients}\n",
    "\n",
    "    if kwargs.get('latex', False):    \n",
    "        # Use LaTeX for text rendering\n",
    "        plt.rcParams['text.usetex'] = True\n",
    "        plt.rcParams['font.family'] = 'serif'\n",
    "        \n",
    "    # if kwargs.get('ndays', False) or len(values[0]) != len(windows):\n",
    "    #     # Resample windows\n",
    "    #     windows = [windows[i] for i in range(0, len(windows), kwargs.get('ndays', len(windows)//len(values[0])))]\n",
    "    \n",
    "    fig, axs = plt.subplots(len(coefficients), figsize=(12, 2.5), sharex=True, layout='constrained')\n",
    "    flattened_axs = axs.flatten() if len(coefficients) > 1 else [axs]\n",
    "    if kwargs.get('suptitle', False):\n",
    "        fig.suptitle(kwargs.get('suptitle'), fontsize=16)\n",
    "\n",
    "    # Search for outcasts\n",
    "    for i, (coeff, ax) in enumerate(zip(coefficients, flattened_axs)):\n",
    "        for j, (start_date, end_date) in enumerate(windows):\n",
    "                # See where the max is zero and label it as outcast\n",
    "                if values[i, j] == -1:\n",
    "                    outcasts[coeff].append((start_date, end_date))\n",
    "        print(f\"Outcasts for {coeff}: {len(outcasts[coeff])}\")\n",
    "\n",
    "        # Create a TwoSlopeNorm\n",
    "        norm = colors.TwoSlopeNorm(vmin=0, vcenter=0.05, vmax=1)\n",
    "        pmesh = ax.pcolormesh(values[i].reshape(1, -1), \n",
    "                              cmap='coolwarm', norm=norm,\n",
    "                              edgecolors='w', linewidth=kwargs.get('linewidth', 0)\n",
    "                              )\n",
    "        # Add ticks to the plot\n",
    "        add_ticks(ax, windows, coeff, outcasts[coeff], **kwargs)\n",
    "        # Set the colorbar for each plot showing only maximum and minimum values\n",
    "    cbar = fig.colorbar(pmesh, ax=axs, orientation='vertical', pad=0.01, ticks=[0, 0.05, 1], aspect=10)\n",
    "    # cbar.set_ticks([0.0, values[i].mean(), values[i].max()])\n",
    "    cbar.ax.set_yticklabels([0, 'Accept\\n' + r'$\\big\\uparrow$' + '\\nThreshold\\n' + r'$\\big\\downarrow$' + '\\nReject', 1], fontsize=11)\n",
    "    \n",
    "    # axs[0].text(0.57, 1.1, '2006-12-31', fontsize=11, transform=axs[0].transAxes, horizontalalignment='left')\n",
    "    # axs[0].text(0.73, 1.1, '2008-12-31', fontsize=11, transform=axs[0].transAxes, horizontalalignment='right')\n",
    "    \n",
    "    # fig.constrained_layout()\n",
    "\n",
    "    plt.show()\n",
    "    return fig, outcasts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ec9a6e2381db5bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rolling Windows"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c144d9dd5cb4c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def roll_windows(duration=250,  start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Create rolling windows of a given duration. \n",
    "    The windows are shifted by one day.\n",
    "    \"\"\"\n",
    "    # Define the start and end dates\n",
    "    start_date = datetime.date(1980, 1, 1) if start_date is None else start_date\n",
    "    end_date = datetime.date(2022, 7, 1) if end_date is None else end_date\n",
    "    \n",
    "    start = start_date + pd.to_timedelta(duration/2, 'D')\n",
    "    end = end_date - pd.to_timedelta(duration/2, 'D')\n",
    "    return [(mid - pd.to_timedelta(duration//2, 'D'), mid + pd.to_timedelta(duration//2, 'D')) for mid in pd.date_range(start, end, freq='D')]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d719cabbead45107"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We can take 250 the approximate number of business days in a year\n",
    "windows = roll_windows(365, start_date=datetime.date(1980, 1, 1), end_date=datetime.date(2022, 7, 1))\n",
    "len(windows)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46a44323cfea3bf2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# If change this, remember to re-generate all the max_values (regenerate=True)\n",
    "coefficients = [\n",
    "    (\"m0p5\", \"m1p5\"), \n",
    "    # (\"0p5\", \"m1p5\"), \n",
    "    (\"0p5\", \"1p5\"),\n",
    "    # (\"1p0\", \"3p0\"),\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0471ab9f498531c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Indexing the Database"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8db215e9e4db4b93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Index columns in the database\n",
    "index_columns = ['Market', 'start', 'end', 'Volatility']\n",
    "for t1, t2 in coefficients:\n",
    "    for name in index_columns:\n",
    "        cur.execute(f'CREATE INDEX IF NOT EXISTS {name.lower()}_index ON stabilvol_{t1}_{t2}({name})')\n",
    "\n",
    "conn.commit()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58e0e0997e8a97b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e9912387f0f9117"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "market = \"UN\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffe89d8f67dd767"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regenerate = False\n",
    "for t1_string, t2_string in coefficients:\n",
    "    if not os.path.exists(f'../data/processed/dynamics/{market}_rolling_MFHT_peaks_{t1_string}_{t2_string}_200bins_{VOL_LIMIT}.pickle') or regenerate:\n",
    "        # Data must be regenerate\n",
    "        print(f\"Generating {market} with thresholds {t1_string}-{t2_string}\")\n",
    "        df, outcasts = create_dataset([market], windows, t1_string, t2_string) \n",
    "        print(f\"There are {len(outcasts[market])} outcasts\")\n",
    "        df.to_pickle(f'../data/processed/dynamics/{market}_rolling_MFHT_peaks_{t1_string}_{t2_string}_200bins_{VOL_LIMIT}.pickle')\n",
    "regenerate = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "171d997b92fc2585"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_values, stat_values, outcasts = test_mfhts(market, windows, NDAYS, coefficients, regenerate=True)\n",
    "# print_rejections(p_values, windows, NDAYS, coefficients) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b07a5fd60f2c9dc4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # With a confidence level of 95%, we must reject the hypothesis that the distributions are the same if the p-value is less than 0.05\n",
    "fig, errors = plot_rolling_pmesh(coefficients, windows, p_values, latex=True, suptitle=market, ndays=NDAYS, label_spacing=365)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29aab472b5884f6e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.savefig(f'../visualization/dynamics/rolling_windows/{market}_rolling_MFHT_p_{NDAYS}days_variousthresholds_{VOL_LIMIT}.png', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/{market}_rolling_MFHT_p_{NDAYS}days_variousthresholds_{VOL_LIMIT}.eps', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/{market}_rolling_MFHT_p_{NDAYS}days_variousthresholds_{VOL_LIMIT}.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6089305ab007ab4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UW"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f27b802506f367c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "market = \"UW\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86afe12978b29e75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regenerate = False\n",
    "for t1_string, t2_string in coefficients:\n",
    "    if not os.path.exists(f'../data/processed/dynamics/{market}_rolling_MFHT_peaks_{t1_string}_{t2_string}_200bins_{VOL_LIMIT}.pickle') or regenerate:\n",
    "        print(f\"Generating {market} with thresholds {t1_string}-{t2_string}\")\n",
    "        # Data must be regenerate\n",
    "        df, outcasts = create_dataset([market], windows, t1_string, t2_string)\n",
    "        print(f\"There are {len(outcasts[market])} outcasts\")\n",
    "        # df['thresholds'] = f'{t1_string}_{t2_string}'\n",
    "        df.to_pickle(f'../data/processed/dynamics/{market}_rolling_MFHT_peaks_{t1_string}_{t2_string}_200bins_{VOL_LIMIT}.pickle')\n",
    "regenerate = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ad87a51740a2560"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_values, stat_values, outcasts = test_mfhts(market, windows, NDAYS, coefficients, regenerate=True)\n",
    "# print_rejections(p_values, windows, NDAYS, coefficients)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe63b38f224ac3e6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " # With a confidence level of 95%, we must reject the hypothesis that the distributions are the same if the p-value is less than 0.05\n",
    "fig, errors = plot_rolling_pmesh(coefficients, windows, p_values, latex=True, suptitle=market, ndays=NDAYS, label_spacing=365)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f1974869b2cfa3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.savefig(f'../visualization/dynamics/rolling_windows/{market}_rolling_MFHT_p_{NDAYS}days_variousthresholds_{VOL_LIMIT}.png', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/{market}_rolling_MFHT_p_{NDAYS}days_variousthresholds_{VOL_LIMIT}.eps', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/{market}_rolling_MFHT_p_{NDAYS}days_variousthresholds_{VOL_LIMIT}.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bf8387f7d4583a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc7d086929334459"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "market = \"LN\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20f94c651cfe135"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regenerate = False\n",
    "for t1_string, t2_string in coefficients:\n",
    "        df = pd.DataFrame()\n",
    "        if not os.path.exists(f'../data/processed/dynamics/{market}_rolling_MFHT_peaks_{t1_string}_{t2_string}_200bins_{VOL_LIMIT}.pickle') or regenerate:\n",
    "            print(f\"Generating {market} with thresholds {t1_string}-{t2_string}\")\n",
    "            # Data must be regenerate\n",
    "            df, outcasts = create_dataset([market], windows, t1_string, t2_string)\n",
    "            print(f\"There are {len(outcasts[market])} outcasts\")\n",
    "            # df['thresholds'] = f'{t1_string}_{t2_string}'\n",
    "            df.to_pickle(f'../data/processed/dynamics/{market}_rolling_MFHT_peaks_{t1_string}_{t2_string}_200bins_{VOL_LIMIT}.pickle')\n",
    "regenerate = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c546b5faa12301d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_values, stat_values, outcasts = test_mfhts(market, windows, NDAYS, coefficients, regenerate=True)\n",
    "# print_rejections(p_values, windows, NDAYS, coefficients)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b643f163aefe545"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# With a confidence level of 95%, we must reject the hypothesis that the distributions are the same if the p-value is less than 0.05\n",
    "fig, errors = plot_rolling_pmesh(coefficients, windows, p_values, latex=True, suptitle=market, ndays=NDAYS, label_spacing=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0bca0c6a42fee72"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.savefig(f'../visualization/dynamics/rolling_windows/{market}_rolling_MFHT_p_{NDAYS}days_variousthresholds_{VOL_LIMIT}.png', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/{market}_rolling_MFHT_p_{NDAYS}days_variousthresholds_{VOL_LIMIT}.eps', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/{market}_rolling_MFHT_p_{NDAYS}days_variousthresholds_{VOL_LIMIT}.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "496687e33c871f0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## JT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7785b7c49f57db61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "market = \"JT\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a179d57a393c748"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regenerate = False\n",
    "for t1_string, t2_string in coefficients:\n",
    "    df = pd.DataFrame()\n",
    "    if not os.path.exists(f'../data/processed/dynamics/{market}_rolling_MFHT_peaks_{t1_string}_{t2_string}_200bins_{VOL_LIMIT}.pickle') or regenerate:\n",
    "        print(f\"Generating {market} with thresholds {t1_string}-{t2_string}\")\n",
    "        # Data must be regenerate\n",
    "        df, outcasts = create_dataset([market], windows, t1_string, t2_string)\n",
    "        print(f\"There are {len(outcasts[market])} outcasts\")\n",
    "        # df['thresholds'] = f'{t1_string}_{t2_string}'\n",
    "        df.to_pickle(f'../data/processed/dynamics/{market}_rolling_MFHT_peaks_{t1_string}_{t2_string}_200bins_{VOL_LIMIT}.pickle')\n",
    "regenerate = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "716433c105fa3593"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_values, stat_values, outcasts = test_mfhts(market, windows, NDAYS, coefficients, regenerate=True)\n",
    "# print_rejections(p_values, windows, NDAYS, coefficients)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1004a6c4b8bc43a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# With a confidence level of 95%, we must reject the hypothesis that the distributions are the same if the p-value is less than 0.05\n",
    "fig, errors = plot_rolling_pmesh(coefficients, windows, p_values, latex=True, suptitle=market, ndays=NDAYS, label_spacing=2, linewidth=0.5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "120d86f7b0c807e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.savefig(f'../visualization/dynamics/rolling_windows/{market}_rolling_MFHT_p_{NDAYS}days_variousthresholds_{VOL_LIMIT}.png', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/{market}_rolling_MFHT_p_{NDAYS}days_variousthresholds_{VOL_LIMIT}.eps', bbox_inches='tight')\n",
    "fig.savefig(f'../visualization/dynamics/rolling_windows/{market}_rolling_MFHT_p_{NDAYS}days_variousthresholds_{VOL_LIMIT}.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ded73644d9d9975f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5fe1060df3b84adf",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
